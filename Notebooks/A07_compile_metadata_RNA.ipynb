{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A07_compile_metadata_RNA overall cmds ===========================================\n",
    "# # just one script to run\n",
    "\n",
    "# qsub Scripts/A07_compile_RNA_metadata.sub # ‡\n",
    "\n",
    "# # ‡ fast enough to run interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for interactive mode, just need to specify working dir & 2 environment variables below\n",
    "# # then comment out the \"%%bash / cat\" lines and run python code in-notebook\n",
    "\n",
    "# import os\n",
    "# os.chdir('../') # move to $dir_proj\n",
    "# os.environ['metadat_well'] = \"Metadata/A01c_well_filepath.csv\"\n",
    "# os.environ['ref_chromsizes'] = \"/u/project/cluo/chliu/Genomes/IGVF_hg38_pluslambda/chromsizes.tsv\"\n",
    "\n",
    "# # alternatively, loop through \"../snmCT_parameters.env\":\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# envvar_needed = ['dir_proj', 'metadat_well']\n",
    "# try:\n",
    "#     os.environ['metadat_well']\n",
    "# except KeyError:\n",
    "#     envspec = pd.read_csv(\"../snmCT_parameters.env\", sep = \"=\", comment=\"#\", header = None\n",
    "#                ).set_axis(['varname', 'varpath'], axis = 1\n",
    "#                ).query('varname in @envvar_needed')\n",
    "#     for index, row in envspec.iterrows():\n",
    "#         os.environ[row[\"varname\"]] = row[\"varpath\"]\n",
    "# os.chdir(os.environ['dir_proj'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07a. DNA+RNA: fastp trimming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07a_trimming.py\n",
    "\n",
    "# A07a_trimming.py =============================================================\n",
    "\n",
    "\n",
    "\n",
    "# setup ========================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_fastp_report(filepath):\n",
    "    jsonfile = pd.read_json(filepath)\n",
    "    dict_out = {\n",
    "        'nreads_pretrim' : jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'percreads_passtrim' : jsonfile['summary']['after_filtering']['total_reads'] /\n",
    "              jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'q20_pretrim' : jsonfile['summary']['before_filtering']['q30_rate'],\n",
    "        'q20_posttrim' : jsonfile['summary']['after_filtering']['q30_rate'],\n",
    "        'r1_len' : jsonfile['summary']['after_filtering']['read1_mean_length'],\n",
    "        'r2_len' : jsonfile['summary']['after_filtering']['read2_mean_length'],\n",
    "        'gc_perc' : jsonfile['summary']['after_filtering']['gc_content']}\n",
    "    return(dict_out)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ==============================================================\n",
    "\n",
    "print(\"\\n\\nfastp .json...\")\n",
    "\n",
    "filelist = metadata_well['A03a_json_fastp']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fastp = [parse_fastp_report(f) for f in filelist[boolean_fileexists]]\n",
    "df_fastp = pd.DataFrame(list_fastp,\n",
    "                        index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_fastp.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_fastp.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07a_trimming.tsv of shape: {}\".format(*df_fastp.shape))\n",
    "df_fastp.to_csv(\"Metadata/A07a_trimming.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07b. RNA: STAR mapping rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07b_RNA_maprate.py\n",
    "\n",
    "# A07b_RNA_maprate.py ==========================================================\n",
    "\n",
    "# setup ------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_star_report(filepath):\n",
    "\n",
    "    \"\"\"\n",
    "    parse STAR.log output\n",
    "    note that paired-end metrics usually fragments, versus reads\n",
    "    \"\"\"\n",
    "    \n",
    "    term_dict = {\n",
    "        'Number of input reads': f'NumReadsIn',\n",
    "        'Average input read length': f'AvgLengthIn',\n",
    "        'Uniquely mapped reads number': f'NumReadsUniqueMapped',\n",
    "        'Uniquely mapped reads %': f'PercentReadsUniqueMapped',\n",
    "        'Average mapped length': f'AvgLengthMapped',\n",
    "        'Number of splices: Total': f'NumTotSplices',\n",
    "        'Number of splices: Annotated (sjdb)': f'NumAnnotSplices',\n",
    "#         'Number of splices: GT/AG': f'NumGTAGSplices',\n",
    "#         'Number of splices: GC/AG': f'NumGCAGSplices',\n",
    "#         'Number of splices: AT/AC': f'NumATACSplices',\n",
    "        'Mismatch rate per base, %': f'RateBaseMismatch',\n",
    "        'Deletion rate per base': f'RateBaseDeletion',\n",
    "        'Deletion average length': f'AvgLengthDeletion',\n",
    "        'Insertion rate per base': f'RateBaseInsertion',\n",
    "        'Insertion average length': f'AvgLengthInsertion',\n",
    "#         'Number of reads mapped to multiple loci': f'NumReadsMultiMap',\n",
    "        '% of reads mapped to multiple loci': f'PercentReadsMultiMap',\n",
    "#         'Number of reads mapped to too many loci': f'NumReadsTooManyLoci',\n",
    "        '% of reads mapped to too many loci': f'PercentReadsTooManyLoci',\n",
    "#         'Number of reads unmapped: too many mismatches': f'NumReadsTooManyMismatch',\n",
    "        '% of reads unmapped: too many mismatches':  f'PercentReadsTooManyMismatch',\n",
    "#         'Number of reads unmapped: too short': f'NumReadsTooShort',\n",
    "        '% of reads unmapped: too short': f'PercentReadsTooShort',\n",
    "#         'Number of reads unmapped: other': f'NumReadsUnmappedOther',\n",
    "        '% of reads unmapped: other': f'PercentReadsUnmappedOther',\n",
    "#         'Number of chimeric reads': f'NumReadsChimeric',\n",
    "#         '% of chimeric reads': f'PercentReadsChimeric',\n",
    "    }\n",
    "    \n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split('|')\n",
    "                lhs = lhs.strip()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().strip('%')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# gather metadata --------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# paired-end -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nPE logs...\")\n",
    "filelist = metadata_well['A06a_txt_star_PE']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_star_PE = [parse_star_report(f) for f in filelist[boolean_fileexists]]\n",
    "df_star_PE = pd.DataFrame(list_star_PE,\n",
    "                           index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_star_PE.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_star_PE.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07b_RNA_maprate_PE.tsv of shape: {}\".format(*df_star_PE.shape))\n",
    "df_star_PE.to_csv(\"Metadata/A07b_RNA_maprate_PE.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# single-end, r1 ---------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE1 logs...\")\n",
    "filelist = metadata_well['A06a_txt_star_SE1']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_star_SE1 = [parse_star_report(f) for f in filelist[boolean_fileexists]]\n",
    "df_star_SE1 = pd.DataFrame(list_star_SE1,\n",
    "                           index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_star_SE1.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_star_SE1.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07b_RNA_maprate_SE1.tsv of shape: {}\".format(*df_star_SE1.shape))\n",
    "df_star_SE1.to_csv(\"Metadata/A07b_RNA_maprate_SE1.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# single-end, r2 ---------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE2 logs...\")\n",
    "filelist = metadata_well['A06a_txt_star_SE2']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_star_SE2 = [parse_star_report(f) for f in filelist[boolean_fileexists]]\n",
    "df_star_SE2 = pd.DataFrame(list_star_SE2,\n",
    "                                  index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_star_SE2.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_star_SE2.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07b_RNA_maprate_SE2.tsv of shape: {}\".format(*df_star_SE2.shape))\n",
    "df_star_SE2.to_csv(\"Metadata/A07b_RNA_maprate_SE2.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07c. RNA deduplication rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07c_RNA_dedupe.py\n",
    "\n",
    "# A07c_RNA_dedupe.py ===========================================================\n",
    "\n",
    "# setup ------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# picard .log files\n",
    "nulltable = np.array([pd.NA, pd.NA, pd.NA]) \n",
    "\n",
    "def parse_picard_dedupe(filepath):\n",
    "    try:\n",
    "        data_dedupe = pd.read_csv(filepath, delimiter = \"\\t\",\n",
    "                         comment = \"#\", nrows = 1)[[\n",
    "                             'UNPAIRED_READS_EXAMINED', 'READ_PAIRS_EXAMINED', 'PERCENT_DUPLICATION'\n",
    "                         ]].transpose()[0]\n",
    "        return(data_dedupe)\n",
    "    except:\n",
    "        print(\"error reading file: \" + filepath)\n",
    "        return(nulltable)\n",
    "\n",
    "tidy_name_dict = {'PERCENT_DUPLICATION' : 'picard_perc_dupe',\n",
    "                  'READ_PAIRS_EXAMINED' : 'picard_npairsin',\n",
    "                  'UNPAIRED_READS_EXAMINED' : 'picard_nreadsin'}\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ==============================================================\n",
    "\n",
    "# paired-end -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nPE logs...\")\n",
    "filelist = metadata_well['A06b_bam_dedupe_PE']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picard_PE = [parse_picard_dedupe(f) for f in filelist[boolean_fileexists]]\n",
    "df_picard_PE = pd.DataFrame(list_picard_PE,\n",
    "                        index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picard_PE.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picard_PE.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07c_RNA_picard_PE.tsv of shape: {}\".format(*df_picard_PE.shape))\n",
    "df_picard_PE.to_csv(\"Metadata/A07c_RNA_picard_PE.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# single-end, read 1 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE1 logs...\")\n",
    "filelist = metadata_well['A06b_bam_dedupe_SE1']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picard_SE1 = [parse_picard_dedupe(f) for f in filelist[boolean_fileexists]]\n",
    "df_picard_SE1 = pd.DataFrame(list_picard_SE1,\n",
    "                        index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picard_SE1.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picard_SE1.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07c_RNA_picard_SE1.tsv of shape: {}\".format(*df_picard_SE1.shape))\n",
    "df_picard_SE1.to_csv(\"Metadata/A07c_RNA_picard_SE1.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# single-end, read 2 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE2 logs...\")\n",
    "filelist = metadata_well['A06b_bam_dedupe_SE2']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picard_SE2 = [parse_picard_dedupe(f) for f in filelist[boolean_fileexists]]\n",
    "df_picard_SE2 = pd.DataFrame(list_picard_SE2,\n",
    "                        index = metadata_well['wellprefix'][boolean_fileexists])\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picard_SE2.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picard_SE2.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07c_RNA_picard_SE2.tsv of shape: {}\".format(*df_picard_SE2.shape))\n",
    "df_picard_SE2.to_csv(\"Metadata/A07c_RNA_picard_SE2.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07d. RNA: feature counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07d_RNA_featcounts.py\n",
    "\n",
    "# A07d_RNA_featcounts.py =======================================================\n",
    "\n",
    "# setup ------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "batchnums = pd.unique(metadata_well['platenum'])\n",
    "\n",
    "\n",
    "def parse_featurecounts(filepath):\n",
    "\n",
    "    featc_summary = pd.read_csv(filepath, delimiter='\\t')\n",
    "    names_samples = [filename.split(\"/\")[1] for filename in featc_summary.columns[1:]]\n",
    "    names_features = featc_summary.iloc[ :, 0]\n",
    "\n",
    "    # calc total read, tidy column names\n",
    "    featc_summary = featc_summary.iloc[:, 1:].transpose()\n",
    "    featc_summary = featc_summary.set_axis(names_samples, axis = 0).set_axis(names_features, axis = 1)\n",
    "    featc_summary['TotalReadsFiltered'] = featc_summary.sum(axis = 1) # from A06c .Aligned.bam --> .Final.bam\n",
    "\n",
    "    # other unassigned features should be zero (non-mapped filtered out)\n",
    "    featc_summary = featc_summary[\n",
    "        ['TotalReadsFiltered', 'Assigned', 'Unassigned_NoFeatures', 'Unassigned_Ambiguity']]\n",
    "    \n",
    "    return(featc_summary)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata --------------------------------------------------------------\n",
    "\n",
    "# gene-level -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\ngene-level quants...\")\n",
    "filelist = pd.Series([\"featurecounts_gene/PE_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcgene_PE = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcgene_PE = pd.concat(list_fcgene_PE)\n",
    "\n",
    "filelist = pd.Series([\"featurecounts_gene/SE1_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcgene_SE1 = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcgene_SE1 = pd.concat(list_fcgene_SE1)\n",
    "\n",
    "filelist = pd.Series([\"featurecounts_gene/SE2_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcgene_SE2 = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcgene_SE2 = pd.concat(list_fcgene_SE2)\n",
    "\n",
    "fcgene_joined = \\\n",
    "    pd.concat([df_fcgene_PE.add_prefix(\"PE_\"),\n",
    "               df_fcgene_SE1.add_prefix(\"SE1_\"),\n",
    "               df_fcgene_SE2.add_prefix(\"SE2_\")], axis = 1\n",
    "               )\n",
    "fcgene_joined.index.names = [\"wellprefix\"]\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(fcgene_joined.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = fcgene_joined.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07d_RNA_featcounts_gene.tsv of shape: {}\".format(*fcgene_joined.shape))\n",
    "fcgene_joined.to_csv(\"Metadata/A07d_RNA_featcounts_gene.tsv\", sep = '\\t')\n",
    "\n",
    "\n",
    "# exon-level -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nexon-level quants...\")\n",
    "filelist = pd.Series([\"featurecounts_exon/PE_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcexon_PE = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcexon_PE = pd.concat(list_fcexon_PE)\n",
    "\n",
    "filelist = pd.Series([\"featurecounts_exon/SE1_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcexon_SE1 = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcexon_SE1 = pd.concat(list_fcexon_SE1)\n",
    "\n",
    "filelist = pd.Series([\"featurecounts_exon/SE2_\" + str(i) + \".summary\" for i in batchnums])\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_fcexon_SE2 = [ parse_featurecounts(f) for f in filelist[boolean_fileexists] ]\n",
    "df_fcexon_SE2 = pd.concat(list_fcexon_SE2)\n",
    "\n",
    "fcexon_joined = \\\n",
    "    pd.concat([df_fcexon_PE.add_prefix(\"PE_\"),\n",
    "               df_fcexon_SE1.add_prefix(\"SE1_\"),\n",
    "               df_fcexon_SE2.add_prefix(\"SE2_\")], axis = 1\n",
    "               )\n",
    "fcexon_joined.index.names = [\"wellprefix\"]\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(fcexon_joined.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = fcexon_joined.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07d_RNA_featcounts_exon.tsv of shape: {}\".format(*fcexon_joined.shape))\n",
    "fcexon_joined.to_csv(\"Metadata/A07d_RNA_featcounts_exon.tsv\", sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07e. RNA: samtools stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07e_RNA_samtools.py\n",
    "\n",
    "# A07e_RNA_samtools.py =========================================================\n",
    "\n",
    "# setup ------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# import samtools stats\n",
    "def parse_samstats(filepath):\n",
    "\n",
    "    term_dict = {\n",
    "        'raw total sequences': f'FilteredSeqCount',\n",
    "        'error rate': f'ErrorRate',\n",
    "        'insert size average': f'InsertSizeAvg',\n",
    "        'insert size standard deviation': f'InsertSizeSD',\n",
    "        }\n",
    "\n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().split('\\t')[0]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata --------------------------------------------------------------\n",
    "\n",
    "\n",
    "# paired-end  ------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nPE logs...\")\n",
    "filelist = metadata_well['A06e_txt_samtools_PE']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_samstats_PE = [parse_samstats(f) for f in filelist[boolean_fileexists]]\n",
    "df_samstats_PE = pd.DataFrame(list_samstats_PE,\n",
    "                               index = metadata_well['wellprefix'][boolean_fileexists]\n",
    ").drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_samstats_PE.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_samstats_PE.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07e_RNA_samstats_PE.tsv of shape: {}\".format(*df_samstats_PE.shape))\n",
    "df_samstats_PE.to_csv(\"Metadata/A07e_RNA_samstats_PE.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# single-end, read 1 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE1 logs...\")\n",
    "filelist = metadata_well['A06e_txt_samtools_SE1']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_samstats_SE1 = [parse_samstats(f) for f in filelist[boolean_fileexists]]\n",
    "df_samstats_SE1 = pd.DataFrame(list_samstats_SE1,\n",
    "                               index = metadata_well['wellprefix'][boolean_fileexists]\n",
    ").drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_samstats_SE1.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_samstats_SE1.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07e_RNA_samstats_SE1.tsv of shape: {}\".format(*df_samstats_SE1.shape))\n",
    "df_samstats_SE1.to_csv(\"Metadata/A07e_RNA_samstats_SE1.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# single-end, read 2 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE2 logs...\")\n",
    "filelist = metadata_well['A06e_txt_samtools_SE2']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_samstats_SE2 = [parse_samstats(f) for f in filelist[boolean_fileexists]]\n",
    "df_samstats_SE2 = pd.DataFrame(list_samstats_SE2,\n",
    "                        index = metadata_well['wellprefix'][boolean_fileexists]\n",
    "                            ).drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_samstats_SE2.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_samstats_SE2.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07e_RNA_samstats_SE2.tsv of shape: {}\".format(*df_samstats_SE2.shape))\n",
    "df_samstats_SE2.to_csv(\"Metadata/A07e_RNA_samstats_SE2.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07f. RNA picard rna metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07f_RNA_picard.py\n",
    "\n",
    "# A07f_RNA_picard.py ===========================================================\n",
    "\n",
    "# setup ------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "filepath_wellmetadat = os.environ['metadat_well']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# read picard log files\n",
    "def parse_picard_rna(filepath):\n",
    "    data_dedupe = pd.read_csv(filepath, delimiter = \"\\t\",\n",
    "                     comment = \"#\", nrows = 1).transpose()[0]\n",
    "    return(data_dedupe)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata --------------------------------------------------------------\n",
    "\n",
    "\n",
    "# paired-end -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nPE logs...\")\n",
    "filelist = metadata_well['A06e_txt_picard_PE']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picardrna_PE = [parse_picard_rna(f) for f in filelist[boolean_fileexists]]\n",
    "df_picardrna_PE = pd.DataFrame(list_picardrna_PE,\n",
    "                               index = metadata_well['wellprefix'][boolean_fileexists]\n",
    "                               ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                                      ).add_prefix(\"picard_\")\n",
    "df_picardrna_PE.columns = df_picardrna_PE.columns.str.lower()\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picardrna_PE.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picardrna_PE.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07f_RNA_picard_PE.tsv of shape: {}\".format(*df_picardrna_PE.shape))\n",
    "df_picardrna_PE.to_csv(\"Metadata/A07f_RNA_picard_PE.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# single-end, read 1 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE1 logs...\")\n",
    "filelist = metadata_well['A06e_txt_picard_SE1']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picardrna_SE1 = [parse_picard_rna(f) for f in filelist[boolean_fileexists]]\n",
    "df_picardrna_SE1 = pd.DataFrame(list_picardrna_SE1,\n",
    "                               index = metadata_well['wellprefix'][boolean_fileexists]\n",
    "                               ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                                      ).add_prefix(\"picard_\")\n",
    "df_picardrna_SE1.columns = df_picardrna_SE1.columns.str.lower()\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picardrna_SE1.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picardrna_SE1.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07f_RNA_picard_SE1.tsv of shape: {}\".format(*df_picardrna_SE1.shape))\n",
    "df_picardrna_SE1.to_csv(\"Metadata/A07f_RNA_picard_SE1.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# single-end, read 2 -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\nSE2 logs...\")\n",
    "filelist = metadata_well['A06e_txt_picard_SE2']\n",
    "boolean_fileexists = [os.path.exists(f) for f in filelist]\n",
    "list_picardrna_SE2 = [parse_picard_rna(f) for f in filelist[boolean_fileexists]]\n",
    "df_picardrna_SE2 = pd.DataFrame(list_picardrna_SE2,\n",
    "                               index = metadata_well['wellprefix'][boolean_fileexists]\n",
    "                               ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                                      ).add_prefix(\"picard_\")\n",
    "df_picardrna_SE2.columns = df_picardrna_SE2.columns.str.lower()\n",
    "\n",
    "\n",
    "# percent files missing\n",
    "print(\"number of target files: \" + str(len(filelist)))\n",
    "print(\"fraction files missing: \")\n",
    "print(round(1 - sum(boolean_fileexists)/len(boolean_fileexists), 3))\n",
    "boolean_filemissing = [not f for f in boolean_fileexists]\n",
    "if sum(boolean_filemissing) != 0:\n",
    "    print(\"missing \" + str(sum(boolean_filemissing)) + \" files:\")\n",
    "    print(filelist[boolean_filemissing].to_string())\n",
    "\n",
    "# column QC\n",
    "print(\"number of NAs per column:\")\n",
    "print(df_picardrna_SE2.isna().sum().to_string())\n",
    "\n",
    "print(\"number of duplicated wells:\")\n",
    "ndupe = df_picardrna_SE2.index.duplicated().sum()\n",
    "print(ndupe)\n",
    "\n",
    "# final export\n",
    "print(\"exporting Metadata/A07f_RNA_picard_SE2.tsv of shape: {}\".format(*df_picardrna_SE2.shape))\n",
    "df_picardrna_SE2.to_csv(\"Metadata/A07f_RNA_picard_SE2.tsv\", sep = '\\t')\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07. run helper script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07_compile_RNA_metadata.sub\n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -o sublogs/A07_compile_RNA.$JOB_ID.$TASK_ID\n",
    "#$ -j y\n",
    "#$ -l h_rt=2:00:00,h_data=8G\n",
    "#$ -N A07_compile_RNA\n",
    "#$ -t 2-6\n",
    "#$ -hold_jid A06a_star,A06b_starfilt,A06d_featurecounts,A06e_samstat_star\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# environment init -------------------------------------------------------------\n",
    "\n",
    ". /u/local/Modules/default/init/modules.sh # <--\n",
    "module load anaconda3 # <--\n",
    "conda activate snmCTseq # <--\n",
    "\n",
    "export $(cat snmCT_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "\n",
    "\n",
    "# run each helper script (A07*) ------------------------------------------------\n",
    "\n",
    "# note: in practice these can each be submitted interactively/as its own task,\n",
    "# as some of these scripts should be much lower resource than others;\n",
    "# the -t 2-6 job parallelization is just for tidyness\n",
    "\n",
    "echo \"metadata script # $SGE_TASK_ID running:\"\n",
    "\n",
    "case $SGE_TASK_ID in\n",
    "\n",
    "  1) # usually already run in A06a; run -t 1-6 instead of 2-6 if not yet run\n",
    "    echo \"python Scripts/A07a_trimming.py\" \n",
    "    python Scripts/A07a_trimming.py\n",
    "    ;;\n",
    "\n",
    "  2)\n",
    "    echo \"python Scripts/A07b_RNA_maprate.py\"\n",
    "    python Scripts/A07b_RNA_maprate.py\n",
    "    ;;\n",
    "\n",
    "  3)\n",
    "    echo \"python Scripts/A07c_RNA_dedupe.py\"\n",
    "    python Scripts/A07c_RNA_dedupe.py\n",
    "    ;;\n",
    "\n",
    "  4)\n",
    "    echo \"python Scripts/A07d_RNA_featcounts.py\"\n",
    "    python Scripts/A07d_RNA_featcounts.py\n",
    "    ;;\n",
    "\n",
    "  5)\n",
    "    echo \"python Scripts/A07e_RNA_samtools.py\"\n",
    "    python Scripts/A07e_RNA_samtools.py\n",
    "    ;;\n",
    "\n",
    "  6)\n",
    "    echo \"python Scripts/A07f_RNA_picard.py\"\n",
    "    python Scripts/A07f_RNA_picard.py\n",
    "    ;;\n",
    "\n",
    "  *)\n",
    "    ;;\n",
    "esac\n",
    "\n",
    "\n",
    "echo \"completed 'A07_compile_RNA_metadata.'\"\n",
    "\n",
    "echo \" \"\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `date `\n",
    "echo \" \"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
