{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## just one script to run\n",
    "# qsub Scripts/A07_compile_RNA_metadata.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07a. DNA+RNA: fastp trimming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07a_trimming.py\n",
    "\n",
    "# A07a_trimming.py =============================================================\n",
    "\n",
    "# don't need to run twice if already obtained in DNA metadata compilation (A06a)\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_fastp_report(filepath):\n",
    "    jsonfile = pd.read_json(filepath)\n",
    "    dict_out = {\n",
    "        'nreads_pretrim' : jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'percreads_passtrim' : jsonfile['summary']['after_filtering']['total_reads'] /\n",
    "              jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'q20_pretrim' : jsonfile['summary']['before_filtering']['q30_rate'],\n",
    "        'q20_posttrim' : jsonfile['summary']['after_filtering']['q30_rate'],\n",
    "        'r1_len' : jsonfile['summary']['after_filtering']['read1_mean_length'],\n",
    "        'r2_len' : jsonfile['summary']['after_filtering']['read2_mean_length'],\n",
    "        'gc_perc' : jsonfile['summary']['after_filtering']['gc_content']}\n",
    "    return(dict_out)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "list_fastp = [parse_fastp_report(file) for file in metadata_well['A03a_json_fastp']]\n",
    "df_fastp = pd.DataFrame(list_fastp,\n",
    "                        index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_fastp)\n",
    "df_fastp.to_csv(\"Metadata/A07a_trimming.tsv\", sep='\\t')\n",
    "del(df_fastp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07b. RNA: STAR mapping rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07b_RNA_maprate.py\n",
    "\n",
    "# A07b_RNA_maprate.py ==========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_star_report(filepath):\n",
    "\n",
    "    \"\"\"\n",
    "    parse STAR.log output\n",
    "    note that paired-end metrics usually fragments, versus reads\n",
    "    \"\"\"\n",
    "    \n",
    "    term_dict = {\n",
    "        'Number of input reads': f'NumReadsIn',\n",
    "        'Average input read length': f'AvgLengthIn',\n",
    "        'Uniquely mapped reads number': f'NumReadsUniqueMapped',\n",
    "        'Uniquely mapped reads %': f'PercentReadsUniqueMapped',\n",
    "        'Average mapped length': f'AvgLengthMapped',\n",
    "        'Number of splices: Total': f'NumTotSplices',\n",
    "        'Number of splices: Annotated (sjdb)': f'NumAnnotSplices',\n",
    "#         'Number of splices: GT/AG': f'NumGTAGSplices',\n",
    "#         'Number of splices: GC/AG': f'NumGCAGSplices',\n",
    "#         'Number of splices: AT/AC': f'NumATACSplices',\n",
    "        'Mismatch rate per base, %': f'RateBaseMismatch',\n",
    "        'Deletion rate per base': f'RateBaseDeletion',\n",
    "        'Deletion average length': f'AvgLengthDeletion',\n",
    "        'Insertion rate per base': f'RateBaseInsertion',\n",
    "        'Insertion average length': f'AvgLengthInsertion',\n",
    "#         'Number of reads mapped to multiple loci': f'NumReadsMultiMap',\n",
    "        '% of reads mapped to multiple loci': f'PercentReadsMultiMap',\n",
    "#         'Number of reads mapped to too many loci': f'NumReadsTooManyLoci',\n",
    "        '% of reads mapped to too many loci': f'PercentReadsTooManyLoci',\n",
    "#         'Number of reads unmapped: too many mismatches': f'NumReadsTooManyMismatch',\n",
    "        '% of reads unmapped: too many mismatches':  f'PercentReadsTooManyMismatch',\n",
    "#         'Number of reads unmapped: too short': f'NumReadsTooShort',\n",
    "        '% of reads unmapped: too short': f'PercentReadsTooShort',\n",
    "#         'Number of reads unmapped: other': f'NumReadsUnmappedOther',\n",
    "        '% of reads unmapped: other': f'PercentReadsUnmappedOther',\n",
    "#         'Number of chimeric reads': f'NumReadsChimeric',\n",
    "#         '% of chimeric reads': f'PercentReadsChimeric',\n",
    "    }\n",
    "    \n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split('|')\n",
    "                lhs = lhs.strip()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().strip('%')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "# paired-end\n",
    "list_star_pe = [parse_star_report(file) for file in metadata_well['A05a_txt_star_PE']]\n",
    "df_star_pe = pd.DataFrame(list_star_pe,\n",
    "                          index= metadata_well['wellprefix'])\n",
    "del(list_star_pe)\n",
    "df_star_pe.to_csv(\"Metadata/A07b_RNA_maprate_PE.tsv\", sep='\\t')\n",
    "del(df_star_pe)\n",
    "\n",
    "# single-end, r1\n",
    "list_star_SE1 = [parse_star_report(file) for file in metadata_well['A05a_txt_star_SE1']]\n",
    "df_star_SE1 = pd.DataFrame(list_star_SE1,\n",
    "                          index= metadata_well['wellprefix'])\n",
    "del(list_star_SE1)\n",
    "df_star_SE1.to_csv(\"Metadata/A07b_RNA_maprate_SE1.tsv\", sep='\\t')\n",
    "del(df_star_SE1)\n",
    "\n",
    "# single-end, r2\n",
    "list_star_SE2 = [parse_star_report(file) for file in metadata_well['A05a_txt_star_SE2']]\n",
    "df_star_SE2 = pd.DataFrame(list_star_SE2,\n",
    "                          index= metadata_well['wellprefix'])\n",
    "del(list_star_SE2)\n",
    "df_star_SE2.to_csv(\"Metadata/A07b_RNA_maprate_SE2.tsv\", sep='\\t')\n",
    "del(df_star_SE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07c. RNA: feature counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07c_RNA_featcounts.py\n",
    "\n",
    "# A07c_RNA_featcounts.py =======================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_featurecounts(filepath):\n",
    "\n",
    "    featc_summary = pd.read_csv(filepath, delimiter='\\t')\n",
    "    names_samples = [filename.split(\"/\")[1] for filename in featc_summary.columns[1:]]\n",
    "    names_features = featc_summary.iloc[ :, 0]\n",
    "\n",
    "    # calc total read, tidy column names\n",
    "    featc_summary = featc_summary.iloc[:, 1:].transpose()\n",
    "    featc_summary = featc_summary.set_axis(names_samples, axis = 0).set_axis(names_features, axis = 1)\n",
    "    featc_summary['TotalReadsFiltered'] = featc_summary.sum(axis = 1) # from A05c .Aligned.bam --> .Final.bam\n",
    "\n",
    "    # other unassigned features should be zero (non-mapped filtered out)\n",
    "    featc_summary = featc_summary[\n",
    "        ['TotalReadsFiltered', 'Assigned', 'Unassigned_NoFeatures', 'Unassigned_Ambiguity']]\n",
    "    \n",
    "    return(featc_summary)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "batchnums=pd.unique(metadata_well['platenum'])\n",
    "\n",
    "# gene-level\n",
    "list_fcgene_PE = [ parse_featurecounts(\"featurecounts_gene/PE_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcgene_PE = pd.concat(list_fcgene_PE)\n",
    "\n",
    "list_fcgene_SE1 = [ parse_featurecounts(\"featurecounts_gene/SE1_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcgene_SE1 = pd.concat(list_fcgene_SE1)\n",
    "\n",
    "list_fcgene_SE2 = [ parse_featurecounts(\"featurecounts_gene/SE2_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcgene_SE2 = pd.concat(list_fcgene_SE2)\n",
    "\n",
    "fcgene_joined = \\\n",
    "    pd.concat([df_fcgene_PE.add_prefix(\"PE_\"),\n",
    "               df_fcgene_SE1.add_prefix(\"SE1_\"),\n",
    "               df_fcgene_SE2.add_prefix(\"SE2_\")], axis = 1\n",
    "               )\n",
    "fcgene_joined.index.names = [\"wellprefix\"]\n",
    "\n",
    "fcgene_joined.to_csv(\"Metadata/A07c_RNA_featcounts_gene.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "# intron-level\n",
    "list_fcexon_PE = [ parse_featurecounts(\"featurecounts_exon/PE_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcexon_PE = pd.concat(list_fcexon_PE)\n",
    "\n",
    "list_fcexon_SE1 = [ parse_featurecounts(\"featurecounts_exon/SE1_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcexon_SE1 = pd.concat(list_fcexon_SE1)\n",
    "\n",
    "list_fcexon_SE2 = [ parse_featurecounts(\"featurecounts_exon/SE2_\" + str(i) + \".summary\")\n",
    "                for i in batchnums ] \n",
    "df_fcexon_SE2 = pd.concat(list_fcexon_SE2)\n",
    "\n",
    "fcexon_joined = \\\n",
    "    pd.concat([df_fcexon_PE.add_prefix(\"PE_\"),\n",
    "               df_fcexon_SE1.add_prefix(\"SE1_\"),\n",
    "               df_fcexon_SE2.add_prefix(\"SE2_\")], axis = 1\n",
    "               )\n",
    "fcexon_joined.index.names = [\"wellprefix\"]\n",
    "\n",
    "fcexon_joined.to_csv(\"Metadata/A07c_RNA_featcounts_exon.tsv\", sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07d. RNA: samtools stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07d_RNA_samtools.py\n",
    "\n",
    "# A07d_RNA_samtools.py =========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# import samtools stats\n",
    "def parse_samstats(filepath):\n",
    "\n",
    "    term_dict = {\n",
    "        'raw total sequences': f'FilteredSeqCount',\n",
    "        'error rate': f'ErrorRate',\n",
    "        'insert size average': f'InsertSizeAvg',\n",
    "        'insert size standard deviation': f'InsertSizeSD',\n",
    "        }\n",
    "\n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().split('\\t')[0]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "# paired-end\n",
    "list_samstats_PE = [parse_samstats(file) for file in metadata_well[\"A05e_txt_samtools_PE\"]]\n",
    "df_samstats_PE = pd.DataFrame(list_samstats_PE,\n",
    "             index = metadata_well[\"wellprefix\"])\n",
    "del(list_samstats_PE)\n",
    "df_samstats_PE.to_csv(\"Metadata/A07d_RNA_samstats_PE.tsv\", sep='\\t')\n",
    "del(df_samstats_PE)\n",
    "\n",
    "\n",
    "# single-end, read 1\n",
    "list_samstats_SE1 = [parse_samstats(file) for file in metadata_well[\"A05e_txt_samtools_SE1\"]]\n",
    "df_samstats_SE1 = pd.DataFrame(list_samstats_SE1,\n",
    "             index = metadata_well[\"wellprefix\"]\n",
    "                               ).drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "del(list_samstats_SE1)\n",
    "df_samstats_SE1.to_csv(\"Metadata/A07d_RNA_samstats_SE1.tsv\", sep='\\t')\n",
    "del(df_samstats_SE1)\n",
    "\n",
    "# single-end, read 2\n",
    "list_samstats_SE2 = [parse_samstats(file) for file in metadata_well[\"A05e_txt_samtools_SE2\"]]\n",
    "df_samstats_SE2 = pd.DataFrame(list_samstats_SE2,\n",
    "             index = metadata_well[\"wellprefix\"]\n",
    "                              ).drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "del(list_samstats_SE2)\n",
    "df_samstats_SE2.to_csv(\"Metadata/A07d_RNA_samstats_SE2.tsv\", sep='\\t')\n",
    "del(df_samstats_SE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A07e. RNA picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07e_RNA_picard.py\n",
    "\n",
    "# A07e_RNA_picard.py ===========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# read picard log files\n",
    "def parse_picard_rna(filepath):\n",
    "    data_dedupe = pd.read_csv(filepath, delimiter = \"\\t\",\n",
    "                     comment = \"#\", nrows = 1).transpose()[0]\n",
    "    return(data_dedupe)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "list_picard_PE = [parse_picard_rna(file) for file in metadata_well['A05e_txt_picard_PE']]\n",
    "df_picard_PE = pd.DataFrame(list_picard_PE,\n",
    "                            index = metadata_well['wellprefix']\n",
    "                           ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                           ).add_prefix(\"picard_\")\n",
    "df_picard_PE.columns = df_picard_PE.columns.str.lower()\n",
    "\n",
    "del(list_picard_PE)\n",
    "df_picard_PE.to_csv(\"Metadata/A07e_RNA_picard_PE.tsv\", sep='\\t')\n",
    "del(df_picard_PE)\n",
    "\n",
    "list_picard_SE1 = [parse_picard_rna(file) for file in metadata_well['A05e_txt_picard_SE1']]\n",
    "df_picard_SE1 = pd.DataFrame(list_picard_SE1,\n",
    "                            index = metadata_well['wellprefix']\n",
    "                           ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                           ).add_prefix(\"picard_\")\n",
    "df_picard_SE1.columns = df_picard_SE1.columns.str.lower()\n",
    "\n",
    "del(list_picard_SE1)\n",
    "df_picard_SE1.to_csv(\"Metadata/A07e_RNA_picard_SE1.tsv\", sep='\\t')\n",
    "del(df_picard_SE1)\n",
    "\n",
    "list_picard_SE2 = [parse_picard_rna(file) for file in metadata_well['A05e_txt_picard_SE2']]\n",
    "df_picard_SE2 = pd.DataFrame(list_picard_SE2,\n",
    "                            index = metadata_well['wellprefix']\n",
    "                           ).drop([\"SAMPLE\", \"LIBRARY\", \"READ_GROUP\"], axis = 1\n",
    "                           ).add_prefix(\"picard_\")\n",
    "df_picard_SE2.columns = df_picard_SE2.columns.str.lower()\n",
    "\n",
    "del(list_picard_SE2)\n",
    "df_picard_SE2.to_csv(\"Metadata/A07e_RNA_picard_SE2.tsv\", sep='\\t')\n",
    "del(df_picard_SE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A07_compile_RNA_metadata.sub\n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -o sublogs/A07_compile_RNA.$JOB_ID.$TASK_ID\n",
    "#$ -j y\n",
    "#$ -l h_rt=6:00:00,h_data=12G\n",
    "#$ -N A07_compile_RNA\n",
    "#$ -t 2-5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "# environment init ------------------—------------------—-----------------------\n",
    "\n",
    ". /u/local/Modules/default/init/modules.sh # <--\n",
    "module load anaconda3 # <--\n",
    "conda activate snmCTseq # <--\n",
    "\n",
    "export $(cat snmCT_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "\n",
    "\n",
    "# run each helper script (A07*) ------------------—------------------—----------\n",
    "\n",
    "# note: in practice these can each be submitted interactively/as its own task,\n",
    "# as some of these scripts should be much lower resource than others;\n",
    "# the -t 2-5 job parallelization is just for tidyness\n",
    "\n",
    "echo \"metadata script # $SGE_TASK_ID running:\"\n",
    "\n",
    "case $SGE_TASK_ID in\n",
    "\n",
    "  1)\n",
    "    echo \"python Scripts/A07a_trimming.py\" # usually already run in A06a\n",
    "    python Scripts/A07a_trimming.py\n",
    "    ;;\n",
    "\n",
    "  2)\n",
    "    echo \"python Scripts/A07b_RNA_maprate.py\"\n",
    "    python Scripts/A07b_RNA_maprate.py\n",
    "    ;;\n",
    "\n",
    "  3)\n",
    "    echo \"python Scripts/A07c_RNA_featcounts.py\"\n",
    "    python Scripts/A07c_RNA_featcounts.py\n",
    "    ;;\n",
    "\n",
    "  4)\n",
    "    echo \"python Scripts/A07d_RNA_samtools.py\"\n",
    "    python Scripts/A07d_RNA_samtools.py\n",
    "    ;;\n",
    "\n",
    "  5)\n",
    "    echo \"python Scripts/A07e_RNA_picard.py\"\n",
    "    python Scripts/A07e_RNA_picard.py\n",
    "    ;;\n",
    "\n",
    "  *)\n",
    "    ;;\n",
    "esac\n",
    "\n",
    "\n",
    "echo \"completed 'A07_compile_RNA_metadata.'\"\n",
    "\n",
    "echo \" \"\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `date `\n",
    "echo \" \"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
