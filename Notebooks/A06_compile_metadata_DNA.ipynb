{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## just one script to run\n",
    "# qsub Scripts/A06_compile_DNA_metadata.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06a. DNA+RNA: fastp trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06a_trimming.py\n",
    "\n",
    "# A06a_trimming.py =============================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_fastp_report(filepath):\n",
    "    jsonfile = pd.read_json(filepath)\n",
    "    dict_out = {\n",
    "        'nreads_pretrim' : jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'percreads_passtrim' : jsonfile['summary']['after_filtering']['total_reads'] /\n",
    "              jsonfile['summary']['before_filtering']['total_reads'],\n",
    "        'q20_pretrim' : jsonfile['summary']['before_filtering']['q30_rate'],\n",
    "        'q20_posttrim' : jsonfile['summary']['after_filtering']['q30_rate'],\n",
    "        'r1_len' : jsonfile['summary']['after_filtering']['read1_mean_length'],\n",
    "        'r2_len' : jsonfile['summary']['after_filtering']['read2_mean_length'],\n",
    "        'gc_perc' : jsonfile['summary']['after_filtering']['gc_content']}\n",
    "    return(dict_out)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "list_fastp = [parse_fastp_report(file) for file in metadata_well['A03a_json_fastp']]\n",
    "df_fastp = pd.DataFrame(list_fastp,\n",
    "                        index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_fastp)\n",
    "df_fastp.to_csv(\"Metadata/A06a_trimming.tsv\", sep='\\t')\n",
    "del(df_fastp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06b. DNA: bismark mapping rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06b_DNA_maprate.py\n",
    "\n",
    "# A06b_DNA_maprate.py ==========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "    \n",
    "def parse_bismark_report(filepath):\n",
    "\n",
    "    \"\"\"\n",
    "    parse bismark.txt output\n",
    "    adapted from YAP @ https://github.com/lhqing/cemba_data to include PE & SE output\n",
    "    commented out term_dict lines of limited interest\n",
    "    note that paired-end metrics usually yield fragments, versus reads\n",
    "    \"\"\"\n",
    "\n",
    "    term_dict = {\n",
    "        'Sequence pairs analysed in total': f'TotalReadPairsIn',\n",
    "        'Sequences analysed in total': f'TotalReadsIn',\n",
    "        'Number of paired-end alignments with a unique best hit': f'UniqueMappedPairs',\n",
    "        'Number of alignments with a unique best hit from the different alignments': f'UniqueMappedReads',\n",
    "        'Mapping efficiency': f'MappingRate',\n",
    "#         'Sequence pairs with no alignments under any condition': f'UnmappedPairs',\n",
    "#         'Sequences with no alignments under any condition': f'UnmappedReads',\n",
    "#         'Sequences did not map uniquely': f'AmbigReads',\n",
    "#         'Sequence pairs did not map uniquely': f'AmbigPairs',\n",
    "#         'CT/GA/CT': f'ReadsOT',\n",
    "#         'GA/CT/CT': f'ReadsOB',\n",
    "#         'GA/CT/GA': f'ReadsCTOT',\n",
    "#         'CT/GA/GA': f'ReadsCTOB',\n",
    "#         'CT/CT': f'ReadsOT',\n",
    "#         'CT/GA': f'ReadsOB',\n",
    "#         'GA/CT': f'ReadsCTOT',\n",
    "#         'GA/GA': f'ReadsCTOB',\n",
    "#         'Total number of C\\'s analysed': f'TotalC',\n",
    "        'C methylated in CpG context': f'BismarkmCGRate',\n",
    "        'C methylated in CHG context': f'BismarkmCHGRate',\n",
    "        'C methylated in CHH context': f'BismarkmCHHRate',\n",
    "        'C methylated in unknown context (CN or CHN)' : f'BismarkmCNCHNRate',\n",
    "        'C methylated in Unknown context (CN or CHN)' : f'BismarkmCNCHNRate'\n",
    "        }\n",
    "\n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().split('\\t')[0].strip('%')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "# paired-end bismark report file\n",
    "\n",
    "list_bismark_PE = [parse_bismark_report(file) for file in metadata_well['A04a_txt_bismark_PE']]\n",
    "df_bismark_PE = pd.DataFrame(list_bismark_PE,\n",
    "                             index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_bismark_PE)\n",
    "df_bismark_PE.to_csv(\"Metadata/A06b_DNA_maprate_PE.tsv\", sep='\\t')\n",
    "del(df_bismark_PE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read 1 singletons from trimming \n",
    "\n",
    "list_bismark_SE1trim = [parse_bismark_report(file) for file in metadata_well['A04a_txt_bismark_SE1trim']]\n",
    "df_bismark_SE1trim = pd.DataFrame(list_bismark_SE1trim,\n",
    "                             index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_bismark_SE1trim)\n",
    "df_bismark_SE1trim.to_csv(\"Metadata/A06b_DNA_maprate_SE1trim.tsv\", sep='\\t')\n",
    "del(df_bismark_SE1trim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read 1 bismark unmapped in PE mode \n",
    "\n",
    "list_bismark_SE1unmap = [parse_bismark_report(file) for file in metadata_well['A04a_txt_bismark_SE1unmap']]\n",
    "df_bismark_SE1unmap = pd.DataFrame(list_bismark_SE1unmap,\n",
    "                             index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_bismark_SE1unmap)\n",
    "df_bismark_SE1unmap.to_csv(\"Metadata/A06b_DNA_maprate_SE1unmap.tsv\", sep='\\t')\n",
    "del(df_bismark_SE1unmap)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read 2 singletons from trimming \n",
    "\n",
    "list_bismark_SE2trim = [parse_bismark_report(file) for file in metadata_well['A04a_txt_bismark_SE2trim']]\n",
    "df_bismark_SE2trim = pd.DataFrame(list_bismark_SE2trim,\n",
    "                             index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_bismark_SE2trim)\n",
    "df_bismark_SE2trim.to_csv(\"Metadata/A06b_DNA_maprate_SE2trim.tsv\", sep='\\t')\n",
    "del(df_bismark_SE2trim)\n",
    "\n",
    "\n",
    "\n",
    "# read 2 bismark unmapped in PE mode \n",
    "\n",
    "list_bismark_SE2unmap = [parse_bismark_report(file) for file in metadata_well['A04a_txt_bismark_SE2unmap']]\n",
    "df_bismark_SE2unmap = pd.DataFrame(list_bismark_SE2unmap,\n",
    "                             index=metadata_well['wellprefix'])\n",
    "\n",
    "del(list_bismark_SE2unmap)\n",
    "df_bismark_SE2unmap.to_csv(\"Metadata/A06b_DNA_maprate_SE2unmap.tsv\", sep='\\t')\n",
    "del(df_bismark_SE2unmap)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06c. DNA: picard deduplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06c_DNA_dedupe.py\n",
    "\n",
    "# A06c_DNA_dedupe.py ===========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# picard .log files\n",
    "nulltable = np.array([pd.NA, pd.NA, pd.NA]) \n",
    "\n",
    "def parse_dedupe(filepath):\n",
    "    try:\n",
    "        data_dedupe = pd.read_csv(filepath, delimiter = \"\\t\",\n",
    "                         comment = \"#\", nrows = 1)[[\n",
    "                             'UNPAIRED_READS_EXAMINED', 'READ_PAIRS_EXAMINED', 'PERCENT_DUPLICATION'\n",
    "                         ]].transpose()[0]\n",
    "        return(data_dedupe)\n",
    "    except:\n",
    "        return(nulltable)\n",
    "\n",
    "tidy_name_dict = {'PERCENT_DUPLICATION' : 'picard_perc_dupe',\n",
    "                  'READ_PAIRS_EXAMINED' : 'picard_npairsin',\n",
    "                  'UNPAIRED_READS_EXAMINED' : 'picard_nreadsin'}\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "# paired end\n",
    "list_picard_PE = [parse_dedupe(file) for file in metadata_well['A04a_txt_picard_PE']]\n",
    "df_picard_PE = pd.DataFrame(list_picard_PE,\n",
    "                            index = metadata_well['wellprefix']\n",
    "                           ).rename(columns = tidy_name_dict\n",
    "                           ).drop(\"picard_nreadsin\", axis = 1)\n",
    "\n",
    "del(list_picard_PE)\n",
    "df_picard_PE.to_csv(\"Metadata/A06c_DNA_picard_PE.tsv\", sep='\\t')\n",
    "del(df_picard_PE)\n",
    "\n",
    "# single end\n",
    "list_picard_SE = [parse_dedupe(file) for file in metadata_well['A04a_txt_picard_SE']]\n",
    "df_picard_SE = pd.DataFrame(list_picard_SE,\n",
    "                            index = metadata_well['wellprefix']\n",
    "                           ).rename(columns = tidy_name_dict\n",
    "                           ).drop(\"picard_npairsin\", axis = 1)\n",
    "\n",
    "del(list_picard_SE)\n",
    "df_picard_SE.to_csv(\"Metadata/A06c_DNA_picard_SE.tsv\", sep='\\t')\n",
    "del(df_picard_SE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06d. DNA: mC fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06d_DNA_mCfracs.py\n",
    "\n",
    "# A06d_DNA_mCfracs.py ==========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "list_mCfracs = [ pd.read_csv(\"Metadata/A04d_mCfrac_\" + str(i) + \".tsv\", delimiter=\"\\t\")\n",
    "                for i in pd.unique(metadata_well['batchnum']) ] \n",
    "df_mCfracs = pd.concat(list_mCfracs)\n",
    "df_mCfracs = df_mCfracs.rename(columns = {\"Well\" : \"wellprefix\"})\n",
    "\n",
    "df_mCfracs.to_csv(\"Metadata/A06d_DNA_compiled_mCfracs.tsv\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06e. DNA: samtools stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06e_DNA_samtools.py\n",
    "\n",
    "# A06e_DNA_samtools.py =========================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_samstats(filepath):\n",
    "\n",
    "    term_dict = {\n",
    "        'raw total sequences': f'FilteredSeqCount',\n",
    "        'error rate': f'ErrorRate',\n",
    "        'insert size average': f'InsertSizeAvg',\n",
    "        'insert size standard deviation': f'InsertSizeSD',\n",
    "        }\n",
    "\n",
    "    with open(filepath) as report:\n",
    "        report_dict = {}\n",
    "        for line in report:\n",
    "            try:\n",
    "                lhs, rhs = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            try:\n",
    "                report_dict[term_dict[lhs]] = rhs.strip().split('\\t')[0]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    return(report_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "# paired-end\n",
    "list_samstats_pe = [parse_samstats(file) for file in metadata_well[\"A04e_txt_samstats_PE\"]]\n",
    "df_samstats_pe = pd.DataFrame(list_samstats_pe,\n",
    "             index = metadata_well[\"wellprefix\"])\n",
    "\n",
    "del(list_samstats_pe)\n",
    "df_samstats_pe.to_csv(\"Metadata/A06e_DNA_samstats_PE.tsv\", sep='\\t')\n",
    "del(df_samstats_pe)\n",
    "\n",
    "\n",
    "# single-end\n",
    "list_samstats_se = [parse_samstats(file) for file in metadata_well[\"A04e_txt_samstats_SE\"]]\n",
    "df_samstats_se = pd.DataFrame(list_samstats_se,\n",
    "                     index = metadata_well[\"wellprefix\"]\n",
    "                             ).drop([\"InsertSizeAvg\", \"InsertSizeSD\"], axis = 1)\n",
    "\n",
    "del(list_samstats_se)\n",
    "df_samstats_se.to_csv(\"Metadata/A06e_DNA_samstats_SE.tsv\", sep='\\t')\n",
    "del(df_samstats_se)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06f. DNA Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06f_DNA_cov.py\n",
    "\n",
    "# A06f_DNA_cov.py ==============================================================\n",
    "\n",
    "# setup ------------------—------------------—----------------------------------\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "filepath_wellmetadat = os.environ['metadat_plate']\n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "target_chroms = [\"chr\" + str(i) for i in range(1, 22)]\n",
    "total_autosomal_bases = \\\n",
    "    pd.read_csv(\"/u/project/cluo/chliu/Genomes/human_gencode_v40/chromsizes.tsv\",\n",
    "                sep = \"\\t\", header = None, index_col = 0).loc[target_chroms, 1].sum()\n",
    "\n",
    "\n",
    "\n",
    "# gather metadata ------------------—------------------—------------------------\n",
    "\n",
    "# unique coverage levels \n",
    "metadata_well = pd.read_csv(filepath_wellmetadat)\n",
    "\n",
    "def parse_coverage_unique(filepath):\n",
    "    try:\n",
    "        percent_coverage = \\\n",
    "            pd.read_csv(filepath, delimiter = \"\\t\", header = None, index_col=0)\n",
    "        percent_coverage = percent_coverage.loc[\n",
    "            np.intersect1d(target_chroms, percent_coverage.index), 1].sum() / total_autosomal_bases\n",
    "    except:\n",
    "        percent_coverage = pd.NA\n",
    "    return(percent_coverage)\n",
    "\n",
    "list_unique = [parse_coverage_unique(file) for file in metadata_well['A04f_txt_covtot']]\n",
    "df_unique = pd.DataFrame(list_unique,\n",
    "                        index = metadata_well['wellprefix'])\n",
    "\n",
    "del(list_unique)\n",
    "df_unique.columns = [\"CoveragePerc1x\"]\n",
    "df_unique.to_csv(\"Metadata/A06f_DNA_cov_percent1x.tsv\", sep='\\t')\n",
    "del(df_unique)\n",
    "\n",
    "# total coverage levels \n",
    "\n",
    "def parse_coverage_total(filepath):\n",
    "    try:\n",
    "        total_cov_by_chr = pd.read_csv(filepath, delimiter = \"\\s+\", header = None, index_col=1)\n",
    "        coverage_XdivY = total_cov_by_chr.loc['chrX', 0] / total_cov_by_chr.loc['chrY', 0]\n",
    "    except:\n",
    "        coverage_XdivY = pd.NA\n",
    "    return(coverage_XdivY)\n",
    "\n",
    "list_total = [parse_coverage_total(file) for file in metadata_well['A04f_txt_covnsites']]\n",
    "df_total = pd.DataFrame(list_total,\n",
    "             index = metadata_well['wellprefix'])\n",
    "\n",
    "del(list_total)\n",
    "df_total.columns = [\"CoverageXdivY\"]\n",
    "df_total.to_csv(\"Metadata/A06f_DNA_cov_chrXdivY.tsv\", sep='\\t')\n",
    "del(df_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06z. run helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A06_compile_DNA_metadata.sub\n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -o sublogs/A06_compile_DNA.$JOB_ID.$TASK_ID\n",
    "#$ -j y\n",
    "#$ -l h_rt=6:00:00,h_data=12G\n",
    "#$ -N A06_compile_DNA\n",
    "#$ -t 1-6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "\n",
    "# environment init ------------------—------------------—-----------------------\n",
    "\n",
    ". /u/local/Modules/default/init/modules.sh # <--\n",
    "module load anaconda3 # <--\n",
    "conda activate snmCTseq # <--\n",
    "\n",
    "export $(cat snmCT_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "\n",
    "\n",
    "# run each helper script (A06*) ------------------—------------------—----------\n",
    "\n",
    "# note: in practice these can each be submitted interactively/as its own task,\n",
    "# as some of these scripts should be much lower resource than others;\n",
    "# however, this -t 1-6 job parallelization is just for tidyness\n",
    "\n",
    "echo \"metadata script # $SGE_TASK_ID running:\"\n",
    "\n",
    "case $SGE_TASK_ID in\n",
    "\n",
    "  1)\n",
    "    echo \"python Scripts/A06a_trimming.py\"\n",
    "    python Scripts/A06a_trimming.py\n",
    "    ;;\n",
    "\n",
    "  2)\n",
    "    echo \"python Scripts/A06b_DNA_maprate.py\"\n",
    "    python Scripts/A06b_DNA_maprate.py\n",
    "    ;;\n",
    "\n",
    "  3)\n",
    "    echo \"python Scripts/A06c_DNA_dedupe.py\"\n",
    "    python Scripts/A06c_DNA_dedupe.py\n",
    "    ;;\n",
    "\n",
    "  4)\n",
    "    echo \"python Scripts/A06d_DNA_mCfracs.py\"\n",
    "    python Scripts/A06d_DNA_mCfracs.py\n",
    "    ;;\n",
    "\n",
    "  5)\n",
    "    echo \"python Scripts/A06e_DNA_samtools.py\"\n",
    "    python Scripts/A06e_DNA_samtools.py\n",
    "    ;;\n",
    "\n",
    "  6)\n",
    "    echo \"python Scripts/A06f_DNA_cov.py\"\n",
    "    python Scripts/A06f_DNA_cov.py\n",
    "    ;;\n",
    "    \n",
    "  *)\n",
    "    ;;\n",
    "esac\n",
    "\n",
    "\n",
    "echo \"completed 'A06_compile_DNA_metadata.'\"\n",
    "\n",
    "echo \" \"\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `date `\n",
    "echo \" \"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
